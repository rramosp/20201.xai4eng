{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LAB 01.02 - Metrics"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["!wget --no-cache -O init.py -q https://raw.githubusercontent.com/rramosp/20201.xai4eng/master/content/init.py\n", "import init, inspect; init.init(force_download=False); init.get_weblink()\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["from local.lib.rlxmoocapi import submit, session\n", "student = session.Session(init.endpoint).login( course_id=init.course_id, \n", "                                                session_id=\"UDEA\", \n", "                                                lab_id=\"L01.02\" )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## General remark\n", "\n", "You do not need to use Python to solve the problems in this notebook, you can use any tool of your choice (Excel, etc.), including **pen and paper**. But\n", "\n", "### If you want to try out in Python\n", "\n", "- `numpy` is the Python library used for vectors\n", "- there are operations that take a vector and produce another vector (i.e. `np.log`)\n", "- there are operations that take a vector and procude a number (i.e. `np.mean`)\n", "- there are operations that take two vectors and produce a number (see the **HINTs** below)\n", "- etc.\n", "\n", "For instance"]}, {"cell_type": "code", "execution_count": 52, "metadata": {"scrolled": true}, "outputs": [], "source": ["import numpy as np\n", "\n", "v1 = np.array([1,2,3,4])\n", "\n", "# the log of each element of the vector\n", "print ( \"the log   =\", np.log(v1)  )\n", "\n", "# the mean of all elements of the vector\n", "print ( \"the mean  =\",  np.mean(v1)  )\n", "\n", "# multiply all elements of a vector with a scalar\n", "print (\"times two =\", 2*v1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["you can always check the type of any variable "]}, {"cell_type": "code", "execution_count": 55, "metadata": {}, "outputs": [], "source": ["a = 2.0\n", "type(v1), type(a)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Task 01. Accuracy\n", "\n", "Compute the percentage of correct predictions **accuracy** (see [here](https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Definitions)) for the following model output (`predicted`) and ground truth (`actual`).\n", "\n", "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n", "\n", "**CHALLENGE**: use Python with [`sklearn.metrics.accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n", "\n", "\n", "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "t1_actual    = np.random.randint(2, size=20)\n", "t1_predicted = np.abs(t1_actual*(np.random.random(size=20)>(np.random.random()*.9+.05)).astype(int))\n", "print (\"actual   \", \", \".join([str(i) for i in t1_actual]))\n", "print (\"predicted\", \", \".join([str(i) for i in t1_predicted]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assign the value of your computation to the `accuracy` variable, **with three decimal places**"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["accuracy = "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### submit your answer"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["student.submit_task(globals(), task_id=\"task_01\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Task 2: Sensitivity\n", "\n", "Compute the sensitivity metric [aka the _True Positive Rate_ or _Recall_ see [Sensitivity on Wikipedia](https://en.wikipedia.org/wiki/Sensitivity_and_specificity)] for the following model output (`predicted`) and ground truth (`actual`)\n", "\n", "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n", "\n", "**Challenge**: Use Python [`sklearn.metrics.recall_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html)\n", "\n", "\n", "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."]}, {"cell_type": "code", "execution_count": 35, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "t2_predicted = np.random.randint(2, size=20)\n", "t2_actual = np.random.randint(2, size=20)\n", "t2_predicted[np.argwhere(t2_actual==1)[0][0]]=0\n", "print (\"actual   \", \", \".join([str(i) for i in t2_actual]))\n", "print (\"predicted\", \", \".join([str(i) for i in t2_predicted]))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assign the value of your computation to the `tpr` variable **with three decimal places**"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["tpr ="]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### submit your answer"]}, {"cell_type": "code", "execution_count": 42, "metadata": {"scrolled": true}, "outputs": [], "source": ["student.submit_task(globals(), task_id=\"task_02\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Task 3: Evaluation in New York City Taxi Trip Duration Kaggle Competition\n", "\n", "Understand the data and the evaluation metric (**Root Mean Squared Logarithmic Error**, RMSLE) of the following Kaggle competition\n", "\n", "- [https://www.kaggle.com/c/nyc-taxi-trip-duration/](https://www.kaggle.com/c/nyc-taxi-trip-duration/)\n", "\n", "Observe that this competition is a **regression task** as we are measuring the difference in prediction with respect to the actual.\n", "\n", "For instance, the following model predictions and ground truth:\n", "\n", "    actual    [66 37 22]\n", "    predicted [79 51 67]\n", "    \n", "produce a **RMSLE** of 0.66 aprox.\n", "\n", "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc.\n", "\n", "**Challenge**: For python use numpy function `np.log` or `np.log1p`\n", "\n", "Observe that every time you execute the following cell, **a different set of values** is generated. You will have to compute the metric **for the values that you see**. If you run the cell again you will have to compute your metric value again."]}, {"cell_type": "code", "execution_count": 57, "metadata": {}, "outputs": [], "source": ["t3_actual    = np.random.randint(80,size=15)+20\n", "t3_predicted = np.random.randint(80,size=15)+20\n", "print (\"actual   \", t3_actual)\n", "print (\"predicted\", t3_predicted)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assign the value of your computation to the `rmsle` variable **with three decimal places**"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [], "source": ["rmsle = "]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### submit your answer"]}, {"cell_type": "code", "execution_count": 73, "metadata": {"scrolled": false}, "outputs": [], "source": ["student.submit_task(globals(), task_id=\"task_03\");"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Task 4: Evaluation in Shelter Animal Outcomes Kaggle Competition\n", "\n", "Understand the data and the evaluation metric (**Multiclass Logaritmic Loss**, _logloss_) of the following Kaggle competition\n", "\n", "- [https://www.kaggle.com/c/shelter-animal-outcomes/](https://www.kaggle.com/c/shelter-animal-outcomes/)\n", "\n", "Observe that this competition is a **classification task with 5 classes** and, for each item, the model produces a probability for each class. Classes are numbered from 0 to 4.\n", "\n", "For instance, the following represents the model output for **three items**\n", "\n", "    [[0.17 0.27 0.03 0.31 0.21]\n", "     [0.09 0.44 0.02 0.15 0.3 ]\n", "     [0.26 0.18 0.25 0.2  0.11]]\n", "     \n", "Where the classes with gretest probability assigned by the model are \n", "\n", "- class 3 for the first item (with 0.31 probability) \n", "- class 1 for the second item (with 0.44 probability)\n", "- class 0 for the third item (with 0.26 probability)\n", "\n", "The class labels are expressed as a similar matrix, but with 0/1\n", "For instance, the ground truth for the corresponding three items above, could be:\n", "\n", "    [[0 0 0 1 0]\n", "     [0 0 1 0 0]\n", "     [1 0 0 0 0]]\n", "\n", "and will produce a **logloss** of approx 2.14\n", "\n", "Execute the following cell to generate the data from which you must compute the metric. You may compute the metric implementing python code, or manually, or copy/pasting the actual and predicted data in Excel, etc."]}, {"cell_type": "code", "execution_count": 74, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "t4_predicted = np.random.random(size=(7,5)).T+0.5\n", "t4_predicted = np.round((t4_predicted/np.sum(t4_predicted,axis=0)),2).T\n", "\n", "t4_actual = np.eye(5)[np.random.randint(5,size=len(t4_predicted))].astype(int)\n", "\n", "print (\"actual\")\n", "print (t4_actual)\n", "print (\"\\npredicted\")\n", "print (t4_predicted)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Assign the value of your computation to the `logloss` variable **with three decimal places**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logloss ="]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### submit your answer"]}, {"cell_type": "code", "execution_count": 84, "metadata": {"scrolled": false}, "outputs": [], "source": ["student.submit_task(globals(), task_id=\"task_04\");"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.6"}}, "nbformat": 4, "nbformat_minor": 2}